{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7ff72-4a8f-4107-837f-f135faabb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628cb0d-4dbc-48dc-9a52-5237850cc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd1fab-8e88-4833-8c5a-40b9df82d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"cure_the_princess_train.csv\")\n",
    "test=pd.read_csv(\"cure_the_princess_test.csv\")\n",
    "validation=pd.read_csv(\"cure_the_princess_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eeba43-6f85-4580-96b6-e8fcbbe0bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c2e90-790b-42f5-9e27-74e375da89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cured.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb157951-b841-4614-bd05-fe0a5c9bc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1c89d-54fd-4bef-9b45-fdb9e974a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Cured.unique()\n",
    "test.Cured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789525d-209a-401f-9d84-e938642f25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.Cured.unique()\n",
    "validation.Cured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa07f4-f7c9-4b7c-85f7-1daaacdf55cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f869e8-8d5f-4429-be80-08e79e776b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb8063-0d87-43cc-afee-9872a65a9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13feb46d-0753-420b-899a-3cfea10a8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbcec7-b575-4168-81f7-bb0d1eb2b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x = validation.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd29e7c-01d3-4311-b9be-ce0155c775d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_y= validation.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33733918-1c93-4d9a-98c7-8718460c6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "train_x = train_x.values\n",
    "train_y = train_y.values\n",
    "\n",
    "train_x = torch.tensor(train_x,dtype = torch.float32)\n",
    "train_y = torch.tensor(train_y,dtype = torch.float32).reshape(-1,1)\n",
    "\n",
    "veri_Dizisi_Train = list()\n",
    "for data in range(len(train_x)):\n",
    "  veri_Dizisi_Train.append([train_x[data],train_y[data]])\n",
    "DL_train = torch.utils.data.DataLoader(veri_Dizisi_Train,batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a9a81-56a1-432a-8989-b5081e8d2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.values\n",
    "test_y = test_y.values\n",
    "\n",
    "test_x = torch.tensor(test_x,dtype = torch.float32)\n",
    "test_y = torch.tensor(test_y,dtype = torch.float32).reshape(-1,1)\n",
    "\n",
    "veri_Dizisi_Test = list()\n",
    "for data in range(len(test_x)):\n",
    "  veri_Dizisi_Test.append([test_x[data],test_y[data]])\n",
    "\n",
    "DL_test = torch.utils.data.DataLoader(veri_Dizisi_Test,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4e0df-a6f2-45b0-ad10-69c935e544f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x = validation_x.values\n",
    "validation_y = validation_y.values\n",
    "\n",
    "validation_x = torch.tensor(validation_x,dtype = torch.float32)\n",
    "validation_y = torch.tensor(validation_y,dtype = torch.float32).reshape(-1,1)\n",
    "\n",
    "veri_Dizisi_Validation = list()\n",
    "for data in range(len(validation_x)):\n",
    "  veri_Dizisi_Validation.append([validation_x[data],validation_y[data]])\n",
    "\n",
    "DL_validation = torch.utils.data.DataLoader(veri_Dizisi_Validation,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40e1c2-23f4-4801-8d3d-d3e9a3e78877",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DL_validation)\n",
    "len(DL_train)\n",
    "len(DL_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2626177-636c-4822-8695-9224aa69bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 190401088\n",
    "torch.manual_seed(SEED)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "input_size = 13\n",
    "hidden_size1 = 100\n",
    "hidden_size2 = 50\n",
    "output_size = 1\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "batch_size = 16\n",
    "num_epochs = 500\n",
    "patience = 15\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "list_train_loss, list_val_loss = [], []\n",
    "best_val_loss = None\n",
    "patience_counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_count = 0.0\n",
    "    for inputs, labels in DL_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_count += 1.0\n",
    "        train_loss += loss.item()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels in DL_validation:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    model.train()\n",
    "    train_loss /= train_count\n",
    "    val_loss /= len(DL_validation)\n",
    "    print(\"Epoch\", epoch, \"Training loss\", train_loss,\"Validation Loss :\",val_loss)\n",
    "    list_train_loss.append(train_loss)\n",
    "    list_val_loss.append(val_loss)\n",
    "    val_score = val_loss\n",
    "    if best_val_loss is None:\n",
    "        best_val_loss = val_score # hafızada patience boyu tutmaya başla\n",
    "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
    "    elif best_val_loss < val_score: # patience counter\n",
    "        patience_counter += 1\n",
    "        print(\"Earlystopping Patience Counter:\",patience_counter)\n",
    "        if patience_counter == patience:\n",
    "            break\n",
    "    else:\n",
    "        best_val_loss = val_score\n",
    "        torch.save(model.state_dict(), \"checkpoint.pt\") # to keep the best model\n",
    "        patience_counter = 0\n",
    "plt.plot(list_train_loss, label=\"Training loss\")\n",
    "plt.plot(list_val_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('Finished Training')\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "model.eval()\n",
    "predicts =[]\n",
    "real_labels = list()\n",
    "with torch.no_grad():\n",
    "    for inputs,label in DL_test:\n",
    "        outputs = model(inputs)\n",
    "        for out in outputs:\n",
    "            predict = round(float(out.data))\n",
    "            predicts.append(predict)\n",
    "        real_labels.extend(label.tolist())\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "print(\"Accuracy score of this model: {}\".format(accuracy_score(real_labels,predicts)))\n",
    "print(classification_report(real_labels,predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06ee77-d98f-43d7-ab3f-3685d00ba064",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 190401088\n",
    "torch.manual_seed(SEED)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out) \n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = out \n",
    "        return out\n",
    "input_size = 13\n",
    "hidden_size1 = 100\n",
    "hidden_size2 = 50\n",
    "output_size = 1\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "batch_size = 16\n",
    "num_epochs = 500\n",
    "patience = 15\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\n",
    "list_train_loss, list_val_loss = [], []\n",
    "best_val_loss = None\n",
    "patience_counter = 0\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_count = 0.0\n",
    "    for inputs, labels in DL_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_count += 1.0\n",
    "        train_loss += loss.item()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels in DL_validation:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    model.train()\n",
    "    train_loss /= train_count\n",
    "    val_loss /= len(DL_validation)\n",
    "    print(\"Epoch\", epoch, \"Training loss\", train_loss,\"Validation Loss :\",val_loss)\n",
    "    list_train_loss.append(train_loss)\n",
    "    list_val_loss.append(val_loss)\n",
    "    val_score = val_loss\n",
    "    if best_val_loss is None:\n",
    "        best_val_loss = val_score \n",
    "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
    "    elif best_val_loss < val_score:\n",
    "        patience_counter += 1\n",
    "        print(\"Earlystopping Patience Counter:\",patience_counter)\n",
    "        if patience_counter == patience:\n",
    "            break\n",
    "    else:\n",
    "        best_val_loss = val_score\n",
    "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
    "        patience_counter = 0\n",
    "print('Finished Training')\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, output_size)\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "model.eval()\n",
    "predicts =[]\n",
    "real_labels = list()\n",
    "with torch.no_grad():\n",
    "    for inputs,label in DL_test:\n",
    "        outputs = model(inputs)\n",
    "        for out in outputs:\n",
    "            predict = round(float(out.data))\n",
    "            predicts.append(predict)\n",
    "        real_labels.extend(label.tolist())\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "print(\"Accuracy score of this model: {}\".format(accuracy_score(real_labels,predicts)))\n",
    "print(classification_report(real_labels,predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db8456-359b-4949-9603-c9cf8585d6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e95bf9-ca18-4e56-89fd-29acc818fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
